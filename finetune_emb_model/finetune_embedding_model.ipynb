{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2twHxPnZvO-"
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztM9i-TZaA6I"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import ast\n",
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoConfig,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_oLajjPc0OE"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fkNAzkbbAl_"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/fc_qa_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_f_-N0Zc16D"
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idX812rEbmYj"
   },
   "outputs": [],
   "source": [
    "def get_common_questions(text):\n",
    "    common_questions = []\n",
    "    for ele in text.split('\\n'):\n",
    "        ele = ele.strip()\n",
    "        if ele.startswith('-'):\n",
    "            ele = ele.replace('-', '')\n",
    "            ele = ele.strip()\n",
    "            common_questions.append(ele)\n",
    "    return common_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PtR2r5MbniU"
   },
   "outputs": [],
   "source": [
    "train['common_questions'] = train['common_questions'].apply(get_common_questions)\n",
    "\n",
    "train['generated_questions'] = train['generated_questions'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQ68lhSAcNzN"
   },
   "outputs": [],
   "source": [
    "user_queries = train['common_questions'].sum()\n",
    "labels = (train['common_questions'].apply(len) * train.index.to_series().apply(lambda x: [x])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "H_kmG2RNHUYO"
   },
   "outputs": [],
   "source": [
    "def calc_top_k_accuracy(top_k_preds, true_labels):\n",
    "    binary_label_masks = []\n",
    "    for top_k_pred, true_label in zip(top_k_preds, true_labels):\n",
    "        if true_label in top_k_pred:\n",
    "            binary_label_masks.append(1)\n",
    "        else:\n",
    "            binary_label_masks.append(0)\n",
    "    accuracy = np.mean(binary_label_masks)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nuhlmagYcoEr",
    "outputId": "22dbeb2e-1732-48bf-d394-df4489fc38d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### intfloat/multilingual-e5-small\n",
      "Accuracy@1: 0.7805907172995781\n",
      "Accuracy@3: 0.8860759493670886\n",
      "Accuracy@5: 0.9282700421940928\n",
      "\n",
      "### intfloat/multilingual-e5-base\n",
      "Accuracy@1: 0.7383966244725738\n",
      "Accuracy@3: 0.890295358649789\n",
      "Accuracy@5: 0.9240506329113924\n",
      "\n",
      "### intfloat/multilingual-e5-large\n",
      "Accuracy@1: 0.7215189873417721\n",
      "Accuracy@3: 0.869198312236287\n",
      "Accuracy@5: 0.9324894514767933\n",
      "\n",
      "### bkai-foundation-models/vietnamese-bi-encoder\n",
      "Accuracy@1: 0.46835443037974683\n",
      "Accuracy@3: 0.7257383966244726\n",
      "Accuracy@5: 0.7890295358649789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name VoVanPhuc/sup-SimCSE-VietNamese-phobert-base. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\n",
      "Accuracy@1: 0.37130801687763715\n",
      "Accuracy@3: 0.5189873417721519\n",
      "Accuracy@5: 0.6455696202531646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_paths = [\n",
    "    'intfloat/multilingual-e5-small',\n",
    "    'intfloat/multilingual-e5-base',\n",
    "    'intfloat/multilingual-e5-large',\n",
    "    'bkai-foundation-models/vietnamese-bi-encoder',\n",
    "    'VoVanPhuc/sup-SimCSE-VietNamese-phobert-base'\n",
    "]\n",
    "\n",
    "for model_path in model_paths:\n",
    "    embed_model = SentenceTransformer(model_path)\n",
    "\n",
    "    desc_embed = embed_model.encode(\n",
    "        train['api_desc'],\n",
    "        batch_size=16,\n",
    "        device='cuda',\n",
    "        convert_to_tensor=True,\n",
    "        normalize_embeddings=True,\n",
    "        # show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    top_1_preds = []\n",
    "    top_3_preds = []\n",
    "    top_5_preds = []\n",
    "    for query in user_queries:\n",
    "        question_embed = embed_model.encode(query, device='cuda', convert_to_tensor=True, normalize_embeddings=True)\n",
    "        scores = question_embed @ desc_embed.T\n",
    "        top_1_pred = scores.argmax(dim=-1).cpu().numpy().tolist()\n",
    "        top_3_pred = scores.topk(3).indices.cpu().tolist()\n",
    "        top_5_pred = scores.topk(5).indices.cpu().tolist()\n",
    "\n",
    "        top_1_preds.append(top_1_pred)\n",
    "        top_3_preds.append(top_3_pred)\n",
    "        top_5_preds.append(top_5_pred)\n",
    "\n",
    "    top_1_acc = accuracy_score(top_1_preds, labels)\n",
    "    top_3_acc = calc_top_k_accuracy(top_3_preds, labels)\n",
    "    top_5_acc = calc_top_k_accuracy(top_5_preds, labels)\n",
    "\n",
    "    print(f'### {model_path}')\n",
    "    print(f'Accuracy@1: {top_1_acc}')\n",
    "    print(f'Accuracy@3: {top_3_acc}')\n",
    "    print(f'Accuracy@5: {top_5_acc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB_On9x9IN3R"
   },
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-y1OKxMOJnnE"
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'model_name': 'intfloat/multilingual-e5-small',\n",
    "    'batch_size': 32,\n",
    "    'max_length': 512,\n",
    "    'epochs': 2,\n",
    "    'learning_rate': 2e-4,\n",
    "    'warmup_steps': 0,\n",
    "    'weight_decay': 0.1,\n",
    "    'intermediate_dropout': 0.,\n",
    "    'num_workers': mp.cpu_count(),\n",
    "    'seed': 252,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "cfg = SimpleNamespace(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BAd3NZChLn4h"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uzWJR576E8IX"
   },
   "outputs": [],
   "source": [
    "class VTNetDataset(Dataset):\n",
    "\tdef __init__(self, encodings_1, encodings_2):\n",
    "\t\tself.encodings_1 = encodings_1\n",
    "\t\tself.encodings_2 = encodings_2\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\titem = {f'{key}_1': torch.tensor(val[idx]) for key, val in self.encodings_1.items()}\n",
    "\t\titem.update(\n",
    "            {f'{key}_2': torch.tensor(val[idx]) for key, val in self.encodings_2.items()}\n",
    "        )\n",
    "\t\treturn item\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.encodings_1.input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "l39uzuqaHkxH"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(tokenizer, questions, descriptions, mode, batch_size, max_length, num_workers):\n",
    "\n",
    "\tencodings_1 = tokenizer(\n",
    "\t\tquestions,\n",
    "\t\tpadding='max_length',\n",
    "\t\ttruncation=True,\n",
    "\t\tmax_length=max_length,\n",
    "\t\treturn_tensors='pt'\n",
    "\t)\n",
    "\n",
    "\tencodings_2 = tokenizer(\n",
    "\t\tdescriptions,\n",
    "\t\tpadding='max_length',\n",
    "\t\ttruncation=True,\n",
    "\t\tmax_length=max_length,\n",
    "\t\treturn_tensors='pt'\n",
    "\t)\n",
    "\n",
    "\tdataset = VTNetDataset(encodings_1, encodings_2)\n",
    "\n",
    "\tif mode == 'train':\n",
    "\t\tdata_loader = DataLoader(\n",
    "\t\t\tdataset=dataset,\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tdrop_last=True,\n",
    "\t\t\tshuffle=True,\n",
    "\t\t\tnum_workers=num_workers\n",
    "\t\t)\n",
    "\n",
    "\telse:\n",
    "\t\tdata_loader = DataLoader(\n",
    "\t\t\tdataset=dataset,\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tdrop_last=False,\n",
    "\t\t\tshuffle=False,\n",
    "\t\t\tnum_workers=num_workers\n",
    "\t\t)\n",
    "\n",
    "\treturn data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "h1v40BwaJWdt"
   },
   "outputs": [],
   "source": [
    "api_questions = train['generated_questions'].sum()\n",
    "api_descriptions = (train['generated_questions'].apply(len) * train['api_desc'].apply(lambda x: [x])).sum()\n",
    "\n",
    "train_dataloader = get_dataloader(\n",
    "    tokenizer=tokenizer,\n",
    "    questions=api_questions,\n",
    "    descriptions=api_descriptions,\n",
    "    mode='train',\n",
    "    batch_size=cfg.batch_size,\n",
    "    max_length=cfg.max_length,\n",
    "    num_workers=cfg.num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "JJIXtMzRSk9R"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=318):\n",
    "\trandom.seed(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\t# os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "\t# torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xjoxNRh_O90X"
   },
   "outputs": [],
   "source": [
    "class MultiNegativesRankingLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Ref: https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MultipleNegativesRankingLoss.py\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=50):\n",
    "        super().__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(reduction='mean')\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, embed_1, embed_2, labels=None):\n",
    "        cosine_scores = (\n",
    "            F.normalize(embed_1) @ F.normalize(embed_2).T\n",
    "        ) * self.scale\n",
    "\n",
    "        labels = torch.tensor(\n",
    "            range(len(cosine_scores)),\n",
    "            dtype=torch.long,\n",
    "            device=cosine_scores.device\n",
    "        )\n",
    "\n",
    "        loss = self.cross_entropy(cosine_scores, labels)\n",
    "        return loss\n",
    "\n",
    "\n",
    "loss_fn = MultiNegativesRankingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-pSZtjl5Q2SK"
   },
   "outputs": [],
   "source": [
    "class TextMeanPooling(nn.Module):\n",
    "    def __init__(self, eps=1e-06):\n",
    "        super(TextMeanPooling, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, token_embeddings, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        mean_embeds = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=self.eps)\n",
    "        return mean_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "iKiuZ1C3QSda"
   },
   "outputs": [],
   "source": [
    "class VTNetEmbedModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(VTNetEmbedModel, self).__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(cfg.model_name)\n",
    "        config.attention_probs_dropout_prob = cfg.intermediate_dropout\n",
    "        config.hidden_dropout_prob = cfg.intermediate_dropout\n",
    "\n",
    "        self.backbone = AutoModel.from_pretrained(cfg.model_name, config=config)\n",
    "        self.backbone.gradient_checkpointing_enable()\n",
    "\n",
    "        self.pooler = TextMeanPooling()\n",
    "        self.loss_fn = MultiNegativesRankingLoss()\n",
    "\n",
    "\n",
    "    def forward(self, input_ids_1, attention_mask_1, input_ids_2, attention_mask_2):\n",
    "        embed_1 = self.backbone(input_ids_1, attention_mask_1).last_hidden_state\n",
    "        embed_2 = self.backbone(input_ids_2, attention_mask_2).last_hidden_state\n",
    "\n",
    "        x_1 = self.pooler(embed_1, attention_mask_1)\n",
    "        x_2 = self.pooler(embed_2, attention_mask_2)\n",
    "\n",
    "        loss = self.loss_fn(x_1, x_2)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmN2G9GLSV21",
    "outputId": "a0a50bc8-2d4b-445d-854b-f48cf39bcbf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2 | Batch: 0/16 | Loss: 1.8027\n",
      "Epoch: 1/2 | Batch: 10/16 | Loss: 0.5589\n",
      "Epoch: 2/2 | Batch: 0/16 | Loss: 1.7778\n",
      "Epoch: 2/2 | Batch: 10/16 | Loss: 0.4032\n"
     ]
    }
   ],
   "source": [
    "set_seed(cfg.seed)\n",
    "train_dataloader = get_dataloader(\n",
    "    tokenizer=tokenizer,\n",
    "    questions=api_questions,\n",
    "    descriptions=api_descriptions,\n",
    "    mode='train',\n",
    "    batch_size=cfg.batch_size,\n",
    "    max_length=cfg.max_length,\n",
    "    num_workers=cfg.num_workers,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(cfg.epochs):\n",
    "\n",
    "    model = VTNetEmbedModel(cfg)\n",
    "    model.to(cfg.device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.weight_decay)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=cfg.warmup_steps,\n",
    "        num_training_steps=len(train_dataloader)*cfg.epochs\n",
    "    )\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        input_ids_1 = batch['input_ids_1'].to(cfg.device)\n",
    "        attention_mask_1 = batch['attention_mask_1'].to(cfg.device)\n",
    "        input_ids_2 = batch['input_ids_2'].to(cfg.device)\n",
    "        attention_mask_2 = batch['attention_mask_2'].to(cfg.device)\n",
    "\n",
    "        with autocast():\n",
    "            loss = model(\n",
    "                input_ids_1=input_ids_1,\n",
    "                attention_mask_1=attention_mask_1,\n",
    "                input_ids_2=input_ids_2,\n",
    "                attention_mask_2=attention_mask_2\n",
    "            )\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        if not batch_idx % 10:\n",
    "            print(\n",
    "                f'Epoch: {epoch + 1}/{cfg.epochs}'\n",
    "                f' | Batch: {batch_idx}/{len(train_dataloader)}'\n",
    "                f' | Loss: {loss.detach().cpu().item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7QcgRbf1VgiC"
   },
   "outputs": [],
   "source": [
    "class ValDataset(Dataset):\n",
    "\tdef __init__(self, encodings):\n",
    "\t\tself.encodings = encodings\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\titem = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\t\treturn item\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.encodings['input_ids'].shape[0]\n",
    "\n",
    "\n",
    "encodings_1 = tokenizer(\n",
    "    user_queries,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=cfg.max_length,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset_1 = ValDataset(encodings_1)\n",
    "val_dataloader_1 = DataLoader(\n",
    "    dataset=val_dataset_1,\n",
    "    batch_size=cfg.batch_size,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.num_workers\n",
    ")\n",
    "\n",
    "\n",
    "encodings_2 = tokenizer(\n",
    "    train['api_desc'].values.tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=cfg.max_length,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset_2 = ValDataset(encodings_2)\n",
    "val_dataloader_2 = DataLoader(\n",
    "    dataset=val_dataset_2,\n",
    "    batch_size=cfg.batch_size,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3DmxtS0lW1_f"
   },
   "outputs": [],
   "source": [
    "pooler = TextMeanPooling()\n",
    "desc_embed = torch.tensor([], device=cfg.device)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in val_dataloader_2:\n",
    "        input_ids = batch['input_ids'].to(cfg.device)\n",
    "        attention_mask = batch['attention_mask'].to(cfg.device)\n",
    "        embed = model.backbone(input_ids, attention_mask).last_hidden_state\n",
    "        mean_embed = pooler(embed, attention_mask)\n",
    "        mean_embed = F.normalize(mean_embed, dim=-1)\n",
    "        desc_embed = torch.cat((desc_embed, mean_embed), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBAYUAPTYMs4",
    "outputId": "65ffb141-33e2-4f7d-b8cc-54ae20a85dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy@1: 0.8734177215189873\n",
      "Accuracy@3: 0.9662447257383966\n",
      "Accuracy@5: 0.9873417721518988\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    top_1_preds = []\n",
    "    top_3_preds = []\n",
    "    top_5_preds = []\n",
    "    for batch in val_dataloader_1:\n",
    "        input_ids = batch['input_ids'].to(cfg.device)\n",
    "        attention_mask = batch['attention_mask'].to(cfg.device)\n",
    "        question_embed = model.backbone(input_ids, attention_mask).last_hidden_state\n",
    "        question_embed = pooler(question_embed, attention_mask)\n",
    "        question_embed = F.normalize(question_embed, dim=-1)\n",
    "        scores = question_embed @ desc_embed.T\n",
    "\n",
    "        top_1_pred = scores.argmax(dim=-1).cpu().numpy().tolist()\n",
    "        top_3_pred = scores.topk(3).indices.cpu().tolist()\n",
    "        top_5_pred = scores.topk(5).indices.cpu().tolist()\n",
    "\n",
    "        top_1_preds.extend(top_1_pred)\n",
    "        top_3_preds.extend(top_3_pred)\n",
    "        top_5_preds.extend(top_5_pred)\n",
    "\n",
    "top_1_acc = accuracy_score(top_1_preds, labels)\n",
    "top_3_acc = calc_top_k_accuracy(top_3_preds, labels)\n",
    "top_5_acc = calc_top_k_accuracy(top_5_preds, labels)\n",
    "\n",
    "print(f'Accuracy@1: {top_1_acc}')\n",
    "print(f'Accuracy@3: {top_3_acc}')\n",
    "print(f'Accuracy@5: {top_5_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77zhoV5WuaE_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
